# arXiv:2507.11233v1 - 通过 SWIPE 增强神经音高估计

本文介绍了一种新的神经音高估计方法，通过结合传统数字信号处理（DSP）特征（SWIPE）和现代神经网络技术，显著提升了音高估计的准确性、鲁棒性和效率。该方法在监督学习和自监督学习设置下均表现优异，为音频处理领域的研究人员提供了新的思路。

---

## 背景介绍

音高（Pitch）在人类感知声音时起着核心作用，因此音高估计是音乐、语音和音频处理中的基础任务。传统方法通常基于倒谱（Cepstrum）、功率谱（Power Spectrum）或自相关函数（Autocorrelation Function）进行估计。

近年来，深度神经网络（DNN）被广泛应用于音高估计任务。典型的架构使用卷积神经网络（CNN）处理原始音频的重叠帧，并通过监督学习预测离散音高候选的分布。尽管这些模型可以达到很高的准确率，但它们通常需要大量带有可靠地面真值音高的训练数据，并且在面对噪声和混响时表现不佳。此外，CNN 模型通常包含数百万参数，不适合低资源环境。

为了解决这些问题，研究者提出了两种方法：一是自监督训练范式（Self-supervised training），无需标注数据；二是将传统 DSP 方法与神经网络结合，以提高效率和鲁棒性。

---

## 工作贡献

本文的核心贡献如下：

1. **SWIPE 性能的重新评估**：尽管 SWIPE 被广泛用作神经音高估计的基线，但其性能被低估。本文发现，原始 SWIPE 算法在自监督设置下的性能优于当前最先进的模型（PESTO）。
   
2. **SWIPE 作为神经网络前端的潜力**：本文将 SWIPE 作为音频前端，结合监督和自监督训练范式，显著提升了音高估计的准确性、鲁棒性、效率和延迟。

3. **开源实现**：作者开源了训练模型和 SWIPE 的 PyTorch 实现，方便研究人员进一步探索和使用。

---

## 方法

### SWIPE 算法

SWIPE（Sawtooth Waveform Inspired Pitch Estimator）通过将输入信号的频谱与锯齿波的频谱进行相似性比较，来估计音高。具体来说，SWIPE 为每个音高候选构建一个频谱核，并通过归一化内积计算相似度得分。

![图表 1: SWIPE 核函数示例](/data3/guofang/peirongcan/PaperIgnition/orchestrator/imgs/2507.11233v1_Figure1.png)

SWIPE 的核函数包含整数倍谐波的余弦波瓣，宽度为 $ f_c/2 $，并衰减以模仿锯齿波的频谱。此外，核函数在谐波之间的中点位置包含负值“谷”，以减少八度误差。作者还使用了 SWIPE’ 变体（去除非素数谐波），以进一步提高性能。

### 神经网络结构

本文在监督和自监督设置下分别设计了神经网络架构：

- **监督模型**：输入为 SWIPE 得分或常量-Q变换（CQT）特征，经过6层1D卷积网络，使用 Toeplitz 矩阵进行降维，最终输出概率分布。

- **自监督模型**：基于 PESTO 架构，使用 SWIPE 得分替换 CQT 特征。通过等变性损失、正则化损失和不变性损失进行训练，确保模型对音高移位具有等变性。

---

## 实验

### 数据集

实验使用了三个常用音高标注数据集：

- **MDB-stem-synth**：包含 230 个独奏音轨，音高标注为完美。
- **PTDB-TUG**：包含 20 个英语说话者的录音，标注间隔为 10ms。
- **MIR-1K**：包含 1000 个中文卡拉 OK 录音，标注间隔为 20ms。

### 基线模型

- **DSP 基线**：PYIN 和 SWIPE。
- **监督基线**：FCNF0++。
- **自监督基线**：PESTO。

### 评估指标

- **Raw Pitch Accuracy (RPA)**：音高预测在地面真值 50 美分（cents）内的帧比例。
- **F-Score**：二分类（有音/无音）的准确率。
- **Overall Accuracy (OA)**：所有帧的准确率。

---

## 结果与讨论

### 监督模型

- **SWIPE-sup** 在 MDB-stem-synth 上的 RPA 与 FCNF0++ 相当，但在 MIR-1K 上的泛化性能更好。
- **CQT-sup** 在有音/无音分类任务中表现最佳。
- 所有模型在 MIR-1K 上的泛化性能均不如 DSP 基线，但 SWIPE-sup 表现最优。

### 自监督模型

- **SWIPE-tiny** 在 MDB-stem-synth 上的 RPA 超过 PESTO，证明了原始 SWIPE 算法的优越性。
- **SWIPE-tiny** 通过 Toeplitz 层对 SWIPE 得分进行细化，将估计误差从 90 美分减少到 30 美分。

![图表 2: SWIPE-tiny 编码器对 SWIPE 得分的细化](/data3/guofang/peirongcan/PaperIgnition/orchestrator/imgs/2507.11233v1_Figure2.png)

### 延迟与准确性权衡

SWIPE 模型通过调整窗口大小（以 2 的幂为单位）可以在延迟和准确性之间进行灵活权衡。例如，在 44.1kHz 采样率下，最小窗口大小为 327ms，显著优于 CQT 所需的 1871ms。

### 噪声鲁棒性

在噪声环境下，SWIPE-tiny 表现出较好的鲁棒性，尤其是与自监督训练目标相比。

---

## 结论

本文通过将 SWIPE 与神经网络结合，展示了传统 DSP 方法在现代音频处理中的潜力。SWIPE 在自监督设置下的性能优于当前最先进的模型，表明其在音高估计任务中的重要性。未来的研究方向包括探索混合训练方法，以及直接从数据中学习 SWIPE 的参数。

---

## 参考文献

1. [1] Cepstrum-based pitch estimation.
2. [2] Power spectrum-based pitch estimation.
3. [3] Sawtooth Waveform Inspired Pitch Estimator (SWIPE).
4. [4] Autocorrelation-based pitch estimation.
5. [5] Neural pitch estimation with CNNs.
6. [6] Self-supervised training for pitch estimation.
7. [7] PESTO: Pitch Estimation with Self-Supervised Transposition-Equivariant Objective.
8. [8] FCNF0++: Supervised neural pitch estimator.
9. [9] MIR-1K dataset.
10. [10] MDB-stem-synth dataset.
11. [11] PTDB-TUG dataset.
12. [12] librosa toolkit for mel scale calculation.
13. [13] Speech Processing Toolkit (SPTK).
14. [14] SWIPE implementation details.
15. [15] SWIPE performance comparison.
16. [16] Neural pitch estimation with CQT.
17. [17] PyTorch implementation of SWIPE.
18. [18] ERB scale for speech data.
19. [19] PESTO model architecture.
20. [20] Evaluation metrics for pitch estimation.
21. [21] mir_eval package for evaluation.
22. [22] Adam optimizer for training.
23. [23] Generalization performance of models.
24. [24] Noise robustness experiments.
25. [25] UK Research and Innovation grant.
26. [26] Acknowledgments and reviewer feedback.